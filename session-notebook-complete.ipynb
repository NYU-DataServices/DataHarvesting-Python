{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Harvesting Data on the Web\n",
    "\n",
    "**Nicholas Wolf and Vicky Steeves, NYU Data Services**\n",
    "\n",
    "Vicky's ORCID: 0000-0003-4298-168X | Nick's ORCID: 0000-0001-5512-6151\n",
    "\n",
    "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This session is an intermediate-to-advanced level class that offers some ideas for how to approach the following common data wrangling needs in research:\n",
    "\n",
    " - Obtain data and load it into a suitable data \"container\" for analysis, often via a web interface, especially an API\n",
    " - Parse the data retrieved via an API and turn it into a useful object for manipulation and analysis\n",
    " - Perform some basic summary counts of records in a dataset and work up a quick visualization\n",
    "\n",
    "## Setup\n",
    "\n",
    "**Project Environment**\n",
    "\n",
    "Download the notebook available at [https://goo.gl/Pnm7Dx](https://goo.gl/Pnm7Dx) and open it in Jupyter Notebook. Alternatively, you can clonse the course materials using\n",
    "\n",
    "<code>git clone https://github.com/NYU-DataServices/DataHarvesting-Python.git</code>\n",
    "\n",
    "**State of New York Socrata API Account**\n",
    "\n",
    "To work with this session's data, you'll need to create an API account with the state of New York's data service. Visit <a href=\"https://data.ny.gov\">data.ny.gov</a> and click on signup to create an account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Web Requests\n",
    "\n",
    "It is not unusual to find open data served directly on the web, without requiring any tokens or authorizations. Although it is not often the practice to provide very large resources via such an entrypoint because of the burden it places on data servers, smaller datasets are frequently available. When it comes to such non-API generated data it is generally easier to work with services that serve the data directly in its native file format, rather than wrapping it in HTML. The latter requires you to parse first the HTML or interpret the HTTP response.\n",
    "\n",
    "As an example, take the motor vehicle accident report <a href=\"https://data.ny.gov/Transportation/Motor-Vehicle-Crashes-Vehicle-Information-Three-Ye/xe9x-a24f\">data found here</a>. One thousand records from this 1.65 million-record dataset can be accessed directly at <a href=\"https://data.ny.gov/resource/cm56-widp.json\">https://data.ny.gov/resource/cm56-widp.json</a> (FYI Firefox has a nice JSON viewer built in when you encounter .json hosted files on the web.)\n",
    "\n",
    "Let's walk through making an HTTP request for that .json data and quickly transforming it into a useful container (a Pandas dataframe) to ready it for use. We'll make use of Python's <a href=\"https://docs.python.org/3/library/json.html\">JSON module</a>, a compact and easy-to-use way of turning JSON into Python's native object types, lists and dictionaries. If you want to anticipate what JSON input will prompt which Python object type output, see this table here: https://docs.python.org/3/library/json.html#json-to-py-table. Note that a JSON array of key-value objects will yield a Python list of dictionaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "mv_data_json = requests.get('https://data.ny.gov/resource/cm56-widp.json')\n",
    "\n",
    "mv_list_recs = json.loads(mv_data_json.text)\n",
    "\n",
    "print(mv_list_recs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pandas**\n",
    "\n",
    "If you haven't yet given a Pandas dataframe a try as a way to manage large arrays of information, give it a go. It <em>is</em> possible to go overboard: not everything needs to be put in a dataframe, especially when a Python list of lists or a dictionary will do. Take a look at how fast we can access subsets of the motor vehicle data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "mv_df = pd.DataFrame(mv_list_recs)\n",
    "\n",
    "display(mv_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(mv_df.number_of_occupants))\n",
    "print(type(mv_df.number_of_occupants.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Bonus: wget direct from web**\n",
    "\n",
    "If you have wget installed on your system, you can use the command line utility wget directly in a Notebook cell.\n",
    "\n",
    "To install wget, visit [http://www.gnu.org/software/wget/](http://www.gnu.org/software/wget/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.nhc.noaa.gov/data/hurdat/hurdat2-nepac-1949-2017-050418.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hurdat2-nepac-1949-2017-050418.txt') as f:\n",
    "    for i in f.readlines()[0:2]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web API Requests\n",
    "\n",
    "For more robust ways of serving up data, i.e. by APIs, we generally need to register an \"app,\" i.e. an application that will be accessing the data, receive at the very least a token (and often a client secret as well) to enable tracked downloads of data, ensure proper access limits, etc.\n",
    "\n",
    "It is very helpful if an API comes with a pre-built library to interface with that server so that you don't have to handle signing requests in HTTP, managing tokens, etc. For example, here is the typical workflow often required for authenticated API interfacing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from requests import Request\n",
    "\n",
    "## This first step is just to authenticate user and receive a token (which may or may not expire) to interface with the API\n",
    "\n",
    "def token_retrieve():\n",
    "    authurl = 'https://TOKEN-API-RETRIEVE-URL'\n",
    "    authparams = {'client_id':'CLIENT-ID',\n",
    "              'response_type':'code',\n",
    "              'scope':'/authenticate',\n",
    "              'redirect_uri':'https://PRE-ESTABLISHED-REDIRECT-URL'\n",
    "    }\n",
    "    \n",
    "    code_token = Request('POST', authurl, params=authparams)\n",
    "    \n",
    "    ## In between step above and below some kind of password authentication takes place.\n",
    "    \n",
    "    tokenurl = 'https://URL-TO-CONFIRM-TOKEN'\n",
    "    \n",
    "    head = {'content-type':'Accept: application/json'}\n",
    "    params = {'client_id':'CLIENT-ID',\n",
    "              'client_secret':'CLIENT-SECRET',\n",
    "              'code':continput,\n",
    "              'grant_type':'authorization_code',\n",
    "              'redirect_uri':'https://PRE-ESTABLISHED-REDIRECT-URL'\n",
    "    }\n",
    "\n",
    "    r = requests.post(tokenurl, data=params)\n",
    "\n",
    "    return json.loads(r.text)['access_token']\n",
    "\n",
    "## Now that we are authenticated we can finally get the data.\n",
    "\n",
    "def get_data(acc_token):\n",
    "    baseurl = 'https://DATA-API-URL'\n",
    "    head = {'Accept': 'application/vnd.orcid+json',\n",
    "            'Authorization':'Bearer ' + acc_token\n",
    "    }\n",
    "    r = requests.get(baseurl + 'API-PARAMETERS', headers=head)\n",
    "    return r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these little mini-apps needs to be configured to work with a given API, and this hasn't even arrived at the question of how best to structure your data responses so that they are easy to work with.\n",
    "\n",
    "Fortunately, we have a nice workable pre-made library for working with this same NY State Socrata API portal. The module is called <a href=\"https://github.com/xmunoz/sodapy/blob/master/examples/basic_queries.py\"><pre>sodapy</pre></a>\n",
    "\n",
    "We'll need to install it:\n",
    "\n",
    "<pre>pip install sodapy</pre>\n",
    "\n",
    "or\n",
    "\n",
    "<pre>easy_install sodaypy</pre>\n",
    "\n",
    "or\n",
    "\n",
    "<pre>conda install sodapy</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Web API Access with Prebuilt Library**\n",
    "\n",
    "Helpfully, this sodapy has a nice means of working specifically with the NY State Socrata platform. Once you have sodapy installed, you'll need to click on the large \"Sign up for an app token!\" button here: https://dev.socrata.com/foundry/data.ny.gov/cm56-widp. Or you can select create a new application and begin registering your API retriever via your State Gov dashboard.\n",
    "\n",
    "One you have created an App, copy and paste the App token somewhere for the next step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sodapy\n",
    "from sodapy import Socrata\n",
    "\n",
    "client = Socrata('data.ny.gov','TOKEN',\n",
    "                username='EMAIL-USERNAME',\n",
    "                password='PASSWORD')\n",
    "\n",
    "results = client.get('cm56-widp', limit=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_records(results)\n",
    "display(results_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What if we need to know if a column's values are unique? In the motor vehicle dataframe, for example, what if we suspect that case_vehicle_id is nonunique but should be? How can we check it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick Frequency Counts on a Subset of Data**\n",
    "\n",
    "If we are interested in, say, the counts of each state to which a vehicle involved in an incident was registered, we can do this quickly in Pandas using a groupby function and summing up counts of those grouped common values. \n",
    "\n",
    "Let's also address that NULL value problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_occs = results_df.dropna(axis=0, how='any', \n",
    "                             subset=['number_of_occupants'])\n",
    "\n",
    "num_occs.number_of_occupants.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same to discover typical numbers of occupants in vehicles:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_df = results_df.dropna(axis=0, how='any',\n",
    "                            subset=['action_prior_to_accident',\n",
    "                                   'number_of_occupants']).groupby(['action_prior_to_accident',\n",
    "                                                                  'number_of_occupants']).size()\n",
    "\n",
    "display(layer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy Plots\n",
    "\n",
    "Finally, let's look at putting this all together with the quick matplot visualization capabilities that work really well in Jupyter Notebook and even integrate nicely with Pandas.\n",
    "\n",
    "Let's work with the water use data provided by NYC's open data portal. Now we are working on the city level and not the state: <a href=\"https://data.cityofnewyork.us/Environment/Water-Consumption-In-The-New-York-City/ia2d-e54m\">Water consumption data from the NYC Open Data portal</a>. Preview the JSON version <a href=\"https://data.cityofnewyork.us/api/views/ia2d-e54m/rows.json?accessType=DOWNLOAD\">here</a>.\n",
    "\n",
    "Our workflow is the same: pull the data in JSON format from the web download, turn it into a dataframe, and then visualize.\n",
    "\n",
    "Note the plotting library we pull in, plus a means (via a magic command) to display the visualization in-line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "water_data = requests.get('https://data.cityofnewyork.us/api/views/ia2d-e54m/rows.json?accessType=DOWNLOAD')\n",
    "\n",
    "water_dictionary = json.loads(water_data.text)\n",
    "\n",
    "full_data = []\n",
    "\n",
    "for row in water_dictionary['data']:\n",
    "    full_data.append(row)\n",
    "    \n",
    "col_names = [col_info['name'] for col_info in water_dictionary['meta']['view']['columns']]\n",
    "\n",
    "water_df = pd.DataFrame(full_data, columns = col_names)\n",
    "\n",
    "display(water_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_df[['NYC Consumption(Million gallons per day)','Per Capita(Gallons per person per day)']] = \\\n",
    "    water_df[['NYC Consumption(Million gallons per day)','Per Capita(Gallons per person per day)']].astype(float)\n",
    "\n",
    "    \n",
    "#ax = water_df.plot(x='Year', y='Per Capita(Gallons per person per day)', \n",
    "              #figsize=(10,10), title='Declining Water Use Over Time')\n",
    "#ax.set_xlabel('Year')\n",
    "#ax.set_ylabel('Per Capita Consumption in Gallons')\n",
    "#plt.show()\n",
    "\n",
    "water_df.plot(x='Year', y='Per Capita(Gallons per person per day)', figsize=(10,10), title='Declining Water Use Over Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    " \n",
    "Try making a new plot that only displays the years 1990 onward.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
